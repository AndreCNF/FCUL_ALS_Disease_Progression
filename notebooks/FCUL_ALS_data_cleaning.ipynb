{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCUL ALS Data Cleaning\n",
    "---\n",
    "\n",
    "Exploring the ALS dataset from Faculdade de CiÃªncias da Universidade de Lisboa (FCUL) with the data from over 1000 patients collected in Portugal.\n",
    "\n",
    "The main goal of this notebook is to prepare a single CSV document that contains all the relevant data to be used when training a machine learning model that predicts disease progression, filtering useless columns and performing imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOdmFzXqF7nq"
   },
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5RrWE9R_Nkl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd              # Pandas to handle the data in dataframes\n",
    "import re                        # re to do regex searches in string data\n",
    "import plotly                    # Plotly for interactive and pretty plots\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime    # datetime to use proper date and time formats\n",
    "import os                        # os handles directory/workspace changes\n",
    "import numpy as np               # NumPy to handle numeric and NaN operations\n",
    "from tqdm import tqdm_notebook   # tqdm allows to track code execution progress\n",
    "import numbers                   # numbers allows to check if data is numeric\n",
    "import torch                     # PyTorch to create and apply deep learning models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import data_utils as du          # Data science and machine learning relevant methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust                 # Debugging in Jupyter Notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# Change to parent directory (presumably \"Documents\")\n",
    "os.chdir(\"../../..\")\n",
    "# Path to the CSV dataset files\n",
    "data_path = 'Datasets/Thesis/FCUL_ALS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.set_pandas_library(lib='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow pandas to show more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 3000)\n",
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_days = 90            # How many days into the future will we predict the use of NIV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df = pd.read_csv(f'{data_path}dataWithoutDunnoNIV.csv')\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.rename(columns={'REF': 'subject_id'}, inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a timestamp column\n",
    "\n",
    "Using `medianDate`, we can define a column that serves as the timestamp, which indicates how many days have gone by since the patient's first data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert column `medianDate` to a datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.medianDate = pd.to_datetime(ALS_proc_df.medianDate, format='%d/%m/%Y')\n",
    "ALS_proc_df.medianDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the difference in days between the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.medianDate = ALS_proc_df.groupby('subject_id').medianDate.diff()\n",
    "ALS_proc_df.medianDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a numeric format and replace the missing values (which are the first sample in each time series) with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.medianDate = ALS_proc_df.medianDate / np.timedelta64(1, 'D')\n",
    "ALS_proc_df.medianDate = ALS_proc_df.medianDate.fillna(0)\n",
    "ALS_proc_df.medianDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename to `ts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.rename(columns={'medianDate': 'ts'}, inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.ts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting unused columns\n",
    "\n",
    "Removing kind of useless columns ('NIV_DATE', 'firstDate', 'lastDate'), ones with too many missing values ('SNIP', 'CervicalFlex', 'CervicalExt') and ones that would give away the labels ('ALS-FRS', 'ALS-FRS-R', 'ALS-FRSb', 'ALS-FRSsUL', 'ALS-FRSsLL', 'ALS-FRSr')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.drop(columns=['NIV_DATE', 'firstDate', 'lastDate', 'SNIP', \n",
    "                          'CervicalFlex', 'CervicalExt', 'ALS-FRS',\n",
    "                          'ALS-FRS-R', 'ALS-FRSb', 'ALS-FRSsUL', \n",
    "                          'ALS-FRSsLL', 'ALS-FRSr'], inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing patients without enough samples to predict one time window\n",
    "\n",
    "Since we want to predict the use of NIV in the next 90 days (time window), it doesn't make any sense to include patients that don't have samples that represent at least 90 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.subject_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.groupby('subject_id').ts.count().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in ALS_proc_df.subject_id.unique():\n",
    "    subject_data = ALS_proc_df[ALS_proc_df.subject_id == patient]\n",
    "    # Check if the current patient only has one clinical visit\n",
    "    if subject_data.ts.max() - subject_data.ts.min() < time_window_days:\n",
    "        # Remove patient's data from the dataframe\n",
    "        ALS_proc_df = ALS_proc_df[ALS_proc_df.subject_id != patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.subject_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.groupby('subject_id').ts.count().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.groupby('subject_id').ts.count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning categorical columns\n",
    "\n",
    "Combining redundant values and one hot encoding categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making \"Gender\" a proper one hot encoded column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df['Gender'] = ALS_proc_df['Gender'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing a bug in the `1R` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df['1R'] = ALS_proc_df['1R'].replace(to_replace='\\\\1', value=1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.search_explore.dataframe_missing_values(ALS_proc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode the remaining categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "ALS_proc_df = du.data_processing.one_hot_encoding_dataframe(ALS_proc_df,\n",
    "                                                            columns=['El Escorial reviewed criteria',\n",
    "                                                                     'Onset form',\n",
    "                                                                     'UMN vs LMN',\n",
    "                                                                     'C9orf72'],\n",
    "                                                            join_rows=True,\n",
    "                                                            join_by=['subject_id', 'ts'],\n",
    "                                                            lower_case=True, \n",
    "                                                            has_nan=True,\n",
    "                                                            inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduxing the UMN vs LMN columns into just 2 clear columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.rename(columns={'UMN vs LMN_lmn': 'LMN',\n",
    "                            'UMN vs LMN_umn': 'UMN'}, inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate both UMN and LMN features if the \"both\" value is 1\n",
    "ALS_proc_df.LMN = ALS_proc_df.apply(lambda df: 1 if df['UMN vs LMN_both'] == 1 or df['LMN'] == 1 else 0, axis=1)\n",
    "ALS_proc_df.UMN = ALS_proc_df.apply(lambda df: 1 if df['UMN vs LMN_both'] == 1 or df['UMN'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"both\" column as it's redundant\n",
    "ALS_proc_df.drop(columns='UMN vs LMN_both', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ALS_proc_df[(ALS_proc_df.UMN == 1) & (ALS_proc_df.LMN == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The previous length matches the number found on the value counts of the original dataframe, corresponding to the value \"both\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the redundant `C9orf72_no` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.drop(columns='C9orf72_no', inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.rename(columns={'C9orf72_yes': 'C9orf72'}, inplace=True)\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize all column names to be lower case and without spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.columns = [col.lower().replace(' ', '_').replace('-', '_') for col in ALS_proc_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIV label\n",
    "\n",
    "In order to predict the use of NIV in the next 3 months, we need to create a shifted version of the \"niv\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df['niv_label'] = ALS_proc_df['niv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.head().niv.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_niv_label_in_row(df, time_window_days=90):\n",
    "    global ALS_proc_df\n",
    "    # Get a list of all the timestamps in the current patient's time series\n",
    "    subject_ts_list = ALS_proc_df[ALS_proc_df.subject_id == df.subject_id].ts\n",
    "    try:\n",
    "        # Try to find the timestamp of a sample that is equal or bigger than \n",
    "        # the current one + the desired time window\n",
    "        closest_ts = subject_ts_list[subject_ts_list >= df.ts+time_window_days].iloc[0]\n",
    "    except IndexError:\n",
    "        # Just use the data from the subject's last sample if there are no \n",
    "        # samples in the desired time window for this subject\n",
    "        closest_ts = subject_ts_list.iloc[-1]\n",
    "    # Check if the patient has been on NIV anytime during the defined time window\n",
    "    if closest_ts > df.ts+time_window_days:\n",
    "        time_window_data = ALS_proc_df[(ALS_proc_df.subject_id == df.subject_id) \n",
    "                                       & (ALS_proc_df.ts < closest_ts)\n",
    "                                       & (ALS_proc_df.ts > df.ts)]\n",
    "    else:\n",
    "        time_window_data = ALS_proc_df[(ALS_proc_df.subject_id == df.subject_id) \n",
    "                                       & (ALS_proc_df.ts <= closest_ts)\n",
    "                                       & (ALS_proc_df.ts > df.ts)]\n",
    "    if time_window_data.empty:\n",
    "        # Just use the last NIV indication when it's the last sample in the subject's\n",
    "        # time series or there are no other samples in the specified time window\n",
    "        time_window_data = ALS_proc_df[(ALS_proc_df.subject_id == df.subject_id) \n",
    "                                       & (ALS_proc_df.ts == df.ts)]\n",
    "    return time_window_data.niv.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALS_proc_df[['subject_id', 'ts', 'niv', 'niv_label']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "ALS_proc_df['niv_label'] = ALS_proc_df.apply(set_niv_label_in_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALS_proc_df[['subject_id', 'ts', 'niv', 'niv_label']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a version of the dataframe without normalization\n",
    "ALS_proc_df.to_csv(f'{data_path}cleaned/FCUL_ALS_cleaned_denorm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing continuous values\n",
    "\n",
    "Continuous data is normalized into z-scores, where 0 represents the mean and an absolute value of 1 corresponds to the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ALS_proc_df = du.data_processing.normalize_data(ALS_proc_df, id_columns=['subject_id', 'ts'])\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation and removal of incomplete data\n",
    "\n",
    "Starting from a last information carried forward technique, the data is initially forward filled. Next, a backward fill is done, as current data of the patient should still be a good indicator of the recent past. Finally, the remaining missing values are filled with zeroes, as it represents the average value of each given feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df[['subject_id', 'ts', 'r', 'p1', 'p2', 'bmi', 'fvc', 'vc', 'mip', 'niv_label']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df = du.data_processing.missing_values_imputation(ALS_proc_df, method='zigzag', id_column='subject_id')\n",
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df[['subject_id', 'ts', 'r', 'p1', 'p2', 'bmi', 'fvc', 'vc', 'mip', 'niv_label']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.to_csv(f'{data_path}cleaned/FCUL_ALS_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_proc_df.columns"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "fcul_als_disease_progression",
   "language": "python",
   "name": "fcul_als_disease_progression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
