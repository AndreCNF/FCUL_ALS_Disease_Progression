{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCUL ALS Model Interpretability\n",
    "---\n",
    "\n",
    "Exploring the ALS dataset from Faculdade de CiÃªncias da Universidade de Lisboa (FCUL) with the data from over 1000 patients collected in Portugal.\n",
    "\n",
    "Using different interpretability approaches so as to understand the outputs of the models trained on FCUL's ALS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOdmFzXqF7nq"
   },
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5RrWE9R_Nkl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd              # Pandas to handle the data in dataframes\n",
    "import re                        # re to do regex searches in string data\n",
    "import plotly                    # Plotly for interactive and pretty plots\n",
    "import plotly.graph_objs as go\n",
    "import os                        # os handles directory/workspace changes\n",
    "import numpy as np               # NumPy to handle numeric and NaN operations\n",
    "from tqdm import tqdm_notebook   # tqdm allows to track code execution progress\n",
    "import torch                     # PyTorch to create and apply deep learning models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import utils                     # Contains auxiliary functions\n",
    "from Time_Series_Dataset import Time_Series_Dataset # Dataset subclass which allows the creation of Dataset objects\n",
    "import shap                      # Model-agnostic interpretability package inspired on Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to parent directory (presumably \"Documents\")\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "# Path to the CSV dataset files\n",
    "data_path = 'Datasets/Thesis/FCUL_ALS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEqFkmlYCGOz"
   },
   "source": [
    "**Important:** Use the following two lines to be able to do plotly plots offline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZCUmUOzCPeI"
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yrzi8YbzDVTH"
   },
   "source": [
    "**Important:** The following function is needed in every Google Colab cell that contains a Plotly chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxyGCedgC6bX"
   },
   "outputs": [],
   "source": [
    "def configure_plotly_browser_state():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to the specified value\n",
    "np.random.seed(utils.random_seed)\n",
    "torch.manual_seed(utils.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data (already processed, just like the model trained on)\n",
    "ALS_df = pd.read_csv(f'{data_path}cleaned/FCUL_ALS_cleaned.csv')\n",
    "ALS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original data (before normalization)\n",
    "orig_ALS_df = pd.read_csv(f'{data_path}cleaned/FCUL_ALS_cleaned_denorm.csv')\n",
    "orig_ALS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnamed index column\n",
    "ALS_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "ALS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnamed index and label columns in the original dataframe\n",
    "orig_ALS_df.drop(columns=['Unnamed: 0', 'niv_label'], inplace=True)\n",
    "orig_ALS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of used features\n",
    "ALS_cols = list(ALS_df.columns)\n",
    "\n",
    "# Remove features that aren't used by the model to predict the label\n",
    "for unused_feature in ['subject_id', 'ts', 'niv_label']:\n",
    "    ALS_cols.remove(unused_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best validation performance\n",
    "model = utils.load_checkpoint('GitHub/FCUL_ALS_Disease_Progression/models/checkpoint_26_04_2019_23_36.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting train and test sets, in tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing the sequence length (number of temporal events) of each sequence (patient)\n",
    "seq_len_df = ALS_df.groupby('subject_id').ts.count().to_frame().sort_values(by='ts', ascending=False)\n",
    "seq_len_dict = dict([(idx, val[0]) for idx, val in list(zip(seq_len_df.index, seq_len_df.values))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients = ALS_df.subject_id.nunique()     # Total number of patients\n",
    "n_inputs = len(ALS_df.columns)               # Number of input features\n",
    "padding_value = 999999                       # Value to be used in the padding\n",
    "\n",
    "# Pad data (to have fixed sequence length) and convert into a PyTorch tensor\n",
    "data = utils.dataframe_to_padded_tensor(ALS_df, seq_len_dict, n_patients, n_inputs, padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object from the data tensor\n",
    "dataset = Time_Series_Dataset(data, ALS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train, validation and test sets data loaders and indices\n",
    "train_dataloader, val_dataloader, test_dataloader, \\\n",
    "train_indices, val_indices, test_indices            = utils.create_train_sets(dataset, test_train_ratio=0.2, \n",
    "                                                                              validation_ratio=0.1, \n",
    "                                                                              batch_size=200, get_indeces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tensor data of the training and test sets\n",
    "# train_data = data[train_indices]\n",
    "# test_data = data[test_indices]\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "test_features, test_labels = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Confirm if AUC, accuracy, F1-score, precision, recall and possibly other metrics give acceptable values for the model\n",
    "# [TODO] Also see if output values go out of the range [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original lengths of the sequences, for the training data\n",
    "x_lengths_train = [seq_len_dict[patient] for patient in list(train_features[:100, 0, 0].numpy())]\n",
    "\n",
    "# Sorted indeces to get the data sorted by sequence length\n",
    "data_sorted_idx = list(np.argsort(x_lengths_train)[::-1])\n",
    "\n",
    "# Sort the x_lengths array by descending sequence length\n",
    "x_lengths_train = [x_lengths_train[idx] for idx in data_sorted_idx]\n",
    "\n",
    "# Sort the features by descending sequence length\n",
    "train_data_exp = train_features[data_sorted_idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original lengths of the sequences, for the test data\n",
    "x_lengths_test = [seq_len_dict[patient] for patient in list(test_features[:10, 0, 0].numpy())]\n",
    "\n",
    "# Sorted indeces to get the data sorted by sequence length\n",
    "data_sorted_idx = list(np.argsort(x_lengths_test)[::-1])\n",
    "\n",
    "# Sort the x_lengths array by descending sequence length\n",
    "x_lengths_test = [x_lengths_test[idx] for idx in data_sorted_idx]\n",
    "\n",
    "# Sort the features by descending sequence length\n",
    "test_data_exp = test_features[data_sorted_idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# Use the first 100 training examples as our background dataset to integrate over\n",
    "# (Ignoring the first 2 features, as they constitute the identifiers 'subject_id' and 'ts')\n",
    "explainer = shap.DeepExplainer(model, train_data_exp[:, :, 2:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explain the predictions of the first 10 patients in the test set\n",
    "# shap_values = explainer.shap_values([test_data_exp[:10, :, 2:], x_lengths_test])\n",
    "shap_values = explainer.shap_values(test_data_exp[:10, :, 2:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the JS visualization code\n",
    "shap.initjs()\n",
    "\n",
    "# Choosing which example to use\n",
    "patient = 0\n",
    "ts = 1\n",
    "\n",
    "# Plot the explanation of one prediction\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[patient][ts], features=test_data_exp[patient, ts, 2:].numpy(), feature_names=ALS_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize the feature values so that the plots are easier to understand\n",
    "test_data_exp_denorm = utils.denormalize_data(orig_ALS_df, test_data_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_exp_denorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_ALS_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Init the JS visualization code\n",
    "shap.initjs()\n",
    "\n",
    "# Choosing which example to use\n",
    "patient = 5\n",
    "ts = 1\n",
    "\n",
    "# Plot the explanation of one prediction\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[patient][ts], features=test_data_exp_denorm[patient, ts, 2:].numpy(), feature_names=ALS_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Init the JS visualization code\n",
    "shap.initjs()\n",
    "\n",
    "# Choosing which example to use\n",
    "patient = 5\n",
    "\n",
    "# Plot the explanation of the predictions for one patient\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[patient], features=test_data_exp_denorm[patient, :, 2:].numpy(), feature_names=ALS_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values.reshape(-1, 48), features=test_data_exp_denorm[:, :, 2:].view(-1, 48).numpy(), feature_names=ALS_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values.reshape(-1, 48), features=test_data_exp_denorm[:, :, 2:].view(-1, 48).numpy(), feature_names=ALS_cols, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values.reshape(-1, 48), features=test_data_exp_denorm[:, :, 2:].view(-1, 48).numpy(), feature_names=ALS_cols, plot_type='violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "* The SHAP values are significantly higher than what I usually see (tends to be between -1 and 1, not between -100000 and 250000).\n",
    "* The output values also seem to be wrong in the patients' force plot, as it goes above 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
